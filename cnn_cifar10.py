# -*- coding: utf-8 -*-
"""CNN_cifar10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12HRDrPrm9Fal1zImHIiSODJkJCcB030W
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import cifar10

import os
import random
import numpy as np
import matplotlib.pyplot as plt

# ignore information messgaes from tensorflow, but we will receieve error messages
os.environ['TFF_CPP_MIN_LOG_LEVEL'] = '2'

# %matplotlib inline

"""#**GPU configaration**
If memory growth is enabled for a PhysicalDevice, the runtime initialization will not allocate all memory on the device.
"""

gpu_device = tf.config.experimental.list_physical_devices('GPU')
print(f"Number of GPU = {len(gpu_device)}")
tf.config.experimental.set_memory_growth(gpu_device[0], True)

"""#**Load dataset**"""

(x_train, y_train), (x_test, y_test) = cifar10.load_data()
print(f"Shape of x_train: {x_train.shape}")
print(f"Shape of y_train: {y_train.shape}")
print()
print(f"Shape of x_test: {x_test.shape}")
print(f"Shape of y_test: {y_test.shape}")

"""#**Display images**"""

img_name = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]
digit = 9 # Change to choose new digit
a = x_train[digit]
plt.imshow(a)
print(f"Image (#{digit}): Which is digit '{img_name[(y_train[digit][0])]}'")

ROWS = 5
COLS = 10
i = 0

plt.figure(figsize=(20,8))
for r in range(ROWS):
    for c in range(COLS):
        plt.subplot(ROWS, COLS, i+1)
        plt.imshow(x_train[i], cmap=plt.cm.gray_r)
        
        plt.xticks([])
        plt.yticks([])
        plt.xlabel(img_name[y_train[i][0]])
        i += 1
plt.tight_layout()
plt.show()

x_train, x_test = x_train / 255.0, x_test / 255.0

digit = 9 # Change to choose new digit
a = x_train[digit].reshape(32,32,3)
plt.imshow(a)
print(f"Image (#{digit}): Which is digit '{img_name[(y_train[digit][0])]}'")

"""#Build the model"""

model = keras.Sequential([
    ## input layer
    keras.Input(shape=(32,32,3)),
    
    ## hidden layers
    layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2,2)),
    layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2,2)),
    layers.Conv2D(filters=512, kernel_size=(3,3), activation='relu'),
    layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2,2)),
    
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    
    ## output layer
    layers.Dense(10, activation='softmax')
])
model.summary()

"""#**Compile the model**
Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:


*   **Loss function** — This measures how accurate the model is during training. You want to minimize this function to "steer" the model in the right direction.
*   **Optimizer** — This is how the model is updated based on the data it sees and its loss function.
*   **Metrics** — Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.




"""

model.compile(
    optimizer='adam', 
    loss='sparse_categorical_crossentropy', 
    metrics=['accuracy']
)

"""#**Train the model**
* **one epoch** = one forward pass and one backward pass of all the training examples
* **batch size** = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.
> * **number of iterations** = number of passes, each pass using [ batch size ] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes).
* **validation_split** last $x$% of your traning data is used as a validation dataset.
Example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.


"""

h = model.fit(x=x_train, y=y_train, epochs=10, batch_size=128, validation_split=0.2)

"""#Plot the training results"""

plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
plt.plot(h.history['accuracy'], 'o-', label='train accuracy')
plt.plot(h.history['val_accuracy'], 'o-', label = 'validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.grid(True)
plt.legend(loc='lower right')

plt.subplot(1,2,2)
plt.plot(h.history['loss'], 'o-', label='train loss')
plt.plot(h.history['val_loss'], 'o-', label='validation loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)
plt.legend(loc='upper right')

plt.show()

"""#Evaluate the model on the test dataset"""

test_loss, test_acc = model.evaluate(x_test, y_test)
print('\nTest accuracy:', test_acc)
print('\nTest Loss:', test_loss)

"""#**Make predictions on the entire test images**"""

predictions = model.predict(x_test)

ROWS = 5
COLS = 10

random_indices = random.sample(range(x_test.shape[0]), ROWS*COLS)
sample_images = x_test[random_indices, :]
sample_labels = y_test[random_indices]
predictions = model.predict(sample_images)

i = 0

plt.figure(figsize=(20,10))
for r in range(ROWS):
    for c in range(COLS):
        plt.subplot(ROWS, COLS, i+1)
        plt.imshow(sample_images[i].reshape(32,32,3))
        plt.xticks([])
        plt.yticks([])
        prediction = np.argmax(predictions[i]) 
        confidence = predictions[i][prediction]
        if sample_labels[i] == prediction:
            plt.xlabel(f"{img_name[prediction]} ({confidence: .2f})", color='b')
        else:
            plt.xlabel(f"{img_name[prediction]} ({confidence: .2f})", color='r')
        plt.ylabel(img_name[sample_labels[i][0]], color='g')
        i += 1
        
plt.tight_layout()
plt.show()